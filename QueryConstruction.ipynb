{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb5a0c5-5841-4de6-8823-244fd8b2e3f1",
   "metadata": {},
   "source": [
    "##### Query construction is process of transforming natural language query into the query language of the database or data source we're interacting with. As a lot of data is structured and stored in relational databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5b8b6f-521d-43ed-94ff-fed82daf4e53",
   "metadata": {},
   "source": [
    "### Text-to-Metadata filter\n",
    "\n",
    "Most vector stores provide the ability to limit your vector search based on metadata. During the embedding process, we can attach metadata key-value pairs to vectors in an index and then later specify filter expressions when you query the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa868df-c6b7-4676-bad6-d8c5aa237df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain_classic.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_postgres.vectorstores import PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad37f13-fa00-4731-b652-a1c8dd15015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = 'postgresql+psycopg://langchain:langchain@localhost:6024/langchain'\n",
    "collection_name = \"Harry_Potter_Complete\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "db = PGVector(\n",
    "    embeddings=embedding_model,\n",
    "    connection=connection,\n",
    "    collection_name=collection_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aa03a2-0bfc-49dc-8b39-09913f1f98d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie\",\n",
    "        type=\"string or list[string]\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", \n",
    "        description=\"A 1-10 rating for the movie\", \n",
    "        type=\"float\"\n",
    "    ),\n",
    "]\n",
    "description = \"Brief summary of a movie\"\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e7ccb-75ca-4b09-9415-b139cf020a9f",
   "metadata": {},
   "source": [
    "#### This is meta-data aware sematic retrieval\n",
    "\n",
    "SelfQueryRetriever lets the LLM rewrite a user query into a structured metadata filter + semantic query, using your defined metadata fields (AttributeInfo) to build SQL/JSONB/Pinecone filters automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9dfeed-89d2-4c54-9d8f-4d2dfb65263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=db,\n",
    "    document_contents=description,\n",
    "    metadata_field_info=fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4dd70ab-19a8-4c45-a729-3daf66fe7901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What's a highly rated (above 8.5) science fiction film?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcd6074-92c4-452c-b032-1d501047d02d",
   "metadata": {},
   "source": [
    "This results in a retriever that will take a user query, and split it into:\n",
    "\n",
    "• A filter to apply on the metadata of each document first\n",
    "\n",
    "• A query to use for semantic search on the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada29e2-9b84-41e8-971b-11a6235aef0d",
   "metadata": {},
   "source": [
    "“Show me the exact structured query the LLM produced.”\n",
    "\n",
    "“How did PGVector apply JSONB filters here?”\n",
    "\n",
    "“Rewrite my metadata fields to avoid ambiguity.”\n",
    "\n",
    "“Why did SelfQueryRetriever decide on this filter operator?”\n",
    "\n",
    "“Show me the final SQL query generated.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74217f-3502-40c6-aad0-7756e908eb03",
   "metadata": {},
   "source": [
    "### Text-to-SQL\n",
    "\n",
    "SQL and relational databases are important sources of structured data, but they don’t interact directly with natural language. Although we can simply use the LLM to translate a user’s query to SQL queries, there is little margin for error.\n",
    "\n",
    "Here are some useful strategies for effective text to SQL translations:\n",
    "\n",
    "Database description\n",
    "\n",
    "To ground SQL queries, an LLM must be provided with an accurate description of the database. One common text-to-SQL prompt employs an idea reported in this paper and others: provide the LLM with a CREATE TABLE description for each table, including column names and types.5\n",
    " \n",
    "We can also provide a few (for instance, three) example rows from the table.\n",
    "\n",
    "Few-shot examples\n",
    "\n",
    "Feeding the prompt with few-shot examples of question-query matches can improve the query generation accuracy. This can be achieved by simply appending standard static examples in the prompt to guide the agent on how it should build queries based on questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34cfca62-791d-4a51-bdf4-79065a82e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import QuerySQLDatabaseTool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_classic.chains.sql_database.query import create_sql_query_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a978b5-5ee5-4e64-be5f-fba1e7f833f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env (langchain)",
   "language": "python",
   "name": "lc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
