{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f82ffad-c3cb-4d3d-9059-d593ce2cbb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_core.documents import Document\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc8206c9-19bc-4679-a1db-703827334920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document, split it into chunks\n",
    "\n",
    "raw_document = TextLoader('data/PlainText.txt').load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(raw_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f7fd435-5133-4e98-84ad-6f2ff3f844b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed each chunk and insert it into the vector store\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "connection = 'postgresql+psycopg://langchain:langchain@localhost:6024/langchain'\n",
    "db = PGVector.from_documents(documents, embedding_model, connection=connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfc031-d58a-4f30-b5a2-bd31a906bda4",
   "metadata": {},
   "source": [
    "#### Q: “How does PGVector store embeddings internally?”\n",
    "\n",
    "#### A: PGVector stores embeddings as:\n",
    "\n",
    "A row in a Postgres table\n",
    "\n",
    "A single vector column = contiguous float array\n",
    "\n",
    "Optional ANN index (IVFFLAT, HNSW)\n",
    "\n",
    "Text + metadata stored in normal columns\n",
    "\n",
    "This gives Postgres native vector search capabilities without external engines.\n",
    "\n",
    "#### Q: “How does from_documents() batch embeddings?”\n",
    "\n",
    "#### A: from_documents() batching pipeline:\n",
    "\n",
    "Split list of docs into batches\n",
    "\n",
    "Embed each batch with one model call\n",
    "\n",
    "Insert each batch into Postgres in one DB operation\n",
    "\n",
    "Return the final PGVector object\n",
    "\n",
    "This batching behavior is essential for speed and avoiding rate limits.\n",
    "\n",
    "#### Q: “What does the table schema created by PGVector look like?”\n",
    "\n",
    "#### A: Main Table\n",
    "\n",
    "CREATE TABLE langchain_pg_embedding (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    collection_id INTEGER REFERENCES langchain_pg_collection(id) ON DELETE CASCADE,\n",
    "    embedding vector(<dim>),        -- pgvector column\n",
    "    document TEXT,                  -- chunk content\n",
    "    metadata JSONB,                 -- metadata for the chunk\n",
    "    ctime TIMESTAMPTZ DEFAULT now() -- insertion timestamp\n",
    ");\n",
    "\n",
    "#### Supporting table:\n",
    "\n",
    "CREATE TABLE langchain_pg_collection (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "#### Q: “How do I query similar vectors from this database?”\n",
    "\n",
    "#### A: Using LangChain PGVector wrapper:\n",
    "\n",
    "results = db.similarity_search(\"What is this text about?\", k=5) # db is the PGVector instance created earlier\n",
    "\n",
    "results -> list of Document objects (page_content, metadata)\n",
    "\n",
    "with scores (if supported version)\n",
    "\n",
    "results_with_scores = db.similarity_search_with_score(\"What is this text about?\", k=5)\n",
    "\n",
    "returns [(Document, score), ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c4e92-0d53-4f6e-919f-ca78cfb20b42",
   "metadata": {},
   "source": [
    "### Things to try:\n",
    "\n",
    "the actual internal code path in LangChain\n",
    "\n",
    "how to override batch size\n",
    "\n",
    "how to manually batch embeddings using LCEL runnables\n",
    "\n",
    "how to profile embedding throughput for large corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c065e839-5653-4092-861b-6a1bc53929b3",
   "metadata": {},
   "source": [
    "#### Exploring the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1cedb5-bc9d-4da3-81cc-d57bb93411e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('langchain_pg_collection',), ('langchain_pg_embedding',)]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    print(conn.execute(text(\"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\")).fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4b746d-5e74-44e6-908e-a9396a824f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('collection_id', 'uuid'), ('embedding', 'USER-DEFINED'), ('cmetadata', 'jsonb'), ('id', 'character varying'), ('document', 'character varying')]\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    print(conn.execute(text(\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name='langchain_pg_embedding'\")).fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af3c2f0a-df88-4916-97e7-880052dbb033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('44778751-7166-4ee5-8af7-73d661893dd1', UUID('ca89a2e2-361a-4ae5-a07a-1dd2b64fedf2'), '[-0.0048253546,0.014394158,-0.028047597,-0.019942425,-0.0017111313,0.038944706,-0.0046864697,-0.05162239,0.0045369016,-0.015113509,0.02340386,0.01800 ... (19113 characters truncated) ... 027007742,0.02321868,0.018047895,-0.0015410865,-0.006816036,-0.029030474,0.013361425,-0.0032353024,0.0074499203,-0.016124874,0.011879988,-0.04754844]', 'A TXT file is\\xa0a type of file that stores plain text without any special formatting, styling, or', {'source': 'data/PlainText.txt'})\n",
      "('2ea11aae-37a0-4f7d-996a-497150e89ac4', UUID('ca89a2e2-361a-4ae5-a07a-1dd2b64fedf2'), '[-0.006112092,-0.003568447,0.002396768,-0.022445498,-0.002253229,0.026664877,-0.03223286,-0.03306071,0.0022982934,-0.013753042,-0.00085205433,0.02615 ... (19058 characters truncated) ... ,-0.01187702,0.033514693,0.010147875,-0.0072103324,-0.012217508,-0.0154221,0.007310476,0.0038955824,0.010975729,-0.015662445,0.008078243,-0.03132489]', 'almost any device using a basic text editor like Notepad on Windows or TextEdit on Mac.\\xa0These files', {'source': 'data/PlainText.txt'})\n",
      "('bc5ef998-a969-40b5-8a1d-38e79ea5444e', UUID('ca89a2e2-361a-4ae5-a07a-1dd2b64fedf2'), '[0.0043910765,0.0021183577,-0.005583268,-0.032107078,0.009780573,0.028454963,-0.0101155685,-0.02982122,0.030609448,-0.017708814,0.022819147,0.0135180 ... (19090 characters truncated) ... 11810254,0.015974715,0.010036746,-0.016644709,-0.023200123,-0.012854654,-0.013038574,0.011120557,0.0018047094,-0.017012548,-0.003767064,-0.024710888]', 'on Mac.\\xa0These files are used for storing simple text documents, source code, and configuration', {'source': 'data/PlainText.txt'})\n",
      "('bc290200-5ee3-49f2-8d54-070cf5685258', UUID('ca89a2e2-361a-4ae5-a07a-1dd2b64fedf2'), '[-0.0009057096,0.004119685,0.0042059426,-0.02859627,0.0015052031,0.035082877,-0.02130919,-0.017638048,0.010744303,-0.020577721,-0.0030345584,0.023544 ... (19182 characters truncated) ... 0.031715363,0.013456257,0.0073284847,-0.035938557,0.019901458,-0.033785556,-0.03328871,0.015692066,0.0005300558,0.010433774,-0.02473191,-0.014574161]', 'and configuration data.', {'source': 'data/PlainText.txt'})\n",
      "('e86f69ca-c119-4178-ad2e-ebe016e23c74', UUID('ca89a2e2-361a-4ae5-a07a-1dd2b64fedf2'), '[-0.012109575,0.008961887,-0.0054132207,-0.023243435,-0.029164562,0.022815723,-0.011581619,0.0049053137,-0.0124971885,-0.026852248,0.028442798,0.0399 ... (19153 characters truncated) ... 496264,-0.007478264,0.0011026931,0.0058509563,0.0119425,0.0040665986,-0.0024459737,-0.008841594,-0.0035520084,-0.009028718,-0.007591875,-0.013559784]', 'Key characteristics', {'source': 'data/PlainText.txt'})\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    rows = conn.execute(text(\"\"\"\n",
    "    SELECT * FROM langchain_pg_embedding LIMIT 5;\n",
    "    \"\"\")).fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ed6494-fa22-4a10-af1a-b8ba0463f2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 44778751-7166-4ee5-8af7-73d661893dd1\n",
      "Document: A TXT file is a type of file that stores plain text without any special formatting, styling, or ...\n",
      "Metadata: {'source': 'data/PlainText.txt'}\n",
      "Embedding length: 19411\n",
      "-----\n",
      "ID: 2ea11aae-37a0-4f7d-996a-497150e89ac4\n",
      "Document: almost any device using a basic text editor like Notepad on Windows or TextEdit on Mac. These files ...\n",
      "Metadata: {'source': 'data/PlainText.txt'}\n",
      "Embedding length: 19356\n",
      "-----\n",
      "ID: bc5ef998-a969-40b5-8a1d-38e79ea5444e\n",
      "Document: on Mac. These files are used for storing simple text documents, source code, and configuration ...\n",
      "Metadata: {'source': 'data/PlainText.txt'}\n",
      "Embedding length: 19388\n",
      "-----\n",
      "ID: bc290200-5ee3-49f2-8d54-070cf5685258\n",
      "Document: and configuration data. ...\n",
      "Metadata: {'source': 'data/PlainText.txt'}\n",
      "Embedding length: 19480\n",
      "-----\n",
      "ID: e86f69ca-c119-4178-ad2e-ebe016e23c74\n",
      "Document: Key characteristics ...\n",
      "Metadata: {'source': 'data/PlainText.txt'}\n",
      "Embedding length: 19451\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for r in rows:\n",
    "    print(\"ID:\", r.id)\n",
    "    print(\"Document:\", r.document[:200], \"...\")\n",
    "    print(\"Metadata:\", r.cmetadata)\n",
    "    print(\"Embedding length:\", len(r.embedding))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdbd958-c5c9-4d89-b29b-1208893c1c14",
   "metadata": {},
   "source": [
    "#### Here the length of embeddings are different because DB driver didn’t know how to decode the vector column, so it returned the raw textual representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9251aee-a3a6-400d-9d57-7a01a8c1c81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "'[-0.0048253546,0.014394158,-0.028047597,-0.019942425,-0.0017111313,0.038944706,-0.0046864697,-0.05162239,0.0045369016,-0.015113509,0.02340386,0.01800516,-0.013803007,-0.00502834,-0.016908327,0.014230\n"
     ]
    }
   ],
   "source": [
    "row = rows[0]\n",
    "print(type(row.embedding))\n",
    "print(repr(row.embedding)[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b6739b-dc71-4660-a169-b4d75a732a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "for row in rows:\n",
    "    vec = ast.literal_eval(row.embedding)\n",
    "    print(len(vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceeb8ce-7358-4b26-be5f-26beac05bc3c",
   "metadata": {},
   "source": [
    "#### Search documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edef8b2c-cf63-4b87-9992-bacff16a8088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e281f62b-dd83-441c-bed8-3a65f2d7b3fa', metadata={'source': 'data/PlainText.txt'}, page_content='computer code or scripts.'),\n",
       " Document(id='4bde5211-7a6d-42b9-8af0-d1fd8868f90b', metadata={'source': 'data/PlainText.txt'}, page_content='computer code or scripts.'),\n",
       " Document(id='1f0a2634-6f39-4747-9677-da40af3ff6bd', metadata={'source': 'data/PlainText.txt'}, page_content='computer code or scripts.'),\n",
       " Document(id='2ea11aae-37a0-4f7d-996a-497150e89ac4', metadata={'source': 'data/PlainText.txt'}, page_content='almost any device using a basic text editor like Notepad on Windows or TextEdit on Mac.\\xa0These files')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar = db.similarity_search(\"computer\", k=4)\n",
    "similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da8521-4a21-4c10-8326-d17176334123",
   "metadata": {},
   "source": [
    "#### How it works:\n",
    "\n",
    "• The search query—in this case, the word query—will be sent to the embeddings\n",
    "model to retrieve its embedding.\n",
    "• Then, it will run a query on Postgres to find the N (in this case 4) previously\n",
    "stored embeddings that are most similar to your query.\n",
    "• Finally, it will fetch the text content and metadata that relates to each of those\n",
    "embeddings.\n",
    "• The model can now return a list of Document sorted by how similar they are to\n",
    "the query—the most similar first, the second most similar after, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e76be30a-0f50-4ae3-a200-51c12e8b0271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5e155954-4d7f-4bc3-b18b-8f25ff48e27e',\n",
       " 'f3bf9ecb-3256-44e6-8d03-7e5246dda7e0']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [str(uuid.uuid4()), str(uuid.uuid4())]\n",
    "db.add_documents([\n",
    "    Document(\n",
    "        page_content=\"there are three cats in the bed\",\n",
    "        metadata={\"location\": \"bed\", \"topic\": \"animals\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"there are also dogs in the bed\",\n",
    "        metadata={\"location\": \"bed\", \"topic\": \"animals\"},\n",
    "        ),\n",
    "    ],\n",
    "    ids=ids,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6473cbf-a4bf-4e0d-8c5c-643c43b12fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete operation\n",
    "db.delete(ids=[\"6f44c5f4-4db2-4b3f-98da-402e2a073f57\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4abe3579-ebd0-4178-a338-fa4a6e35dd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='a80f40cc-c5e3-4afb-b570-ba317a9339a6', metadata={'topic': 'animals', 'location': 'bed'}, page_content='there are three cats in the bed'),\n",
       " Document(id='79077df0-32ef-40fd-a65c-c0da5c2a0eba', metadata={'topic': 'animals', 'location': 'bed'}, page_content='there are three cats in the bed')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar = db.similarity_search(\"cats\", k=2)\n",
    "similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b4f150-c745-4995-a829-c6f7a08d917c",
   "metadata": {},
   "source": [
    "### Tracking changes to the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b991d4-2c64-48bb-9b36-28d01abfcfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "collection_name = \"my_docs\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Example docs\n",
    "docs = [\n",
    "    Document(page_content=\"there are cats in the pond\", metadata={\"source\":\"cats.txt\"}),\n",
    "    Document(page_content=\"there are also ducks in the pond\", metadata={\"source\":\"ducks.txt\"}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66fe05b0-83fa-43b8-a4a2-631f8426e519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats.txt', 'ducks.txt']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the set of source IDs you will index\n",
    "sources = [d.metadata.get(\"source\") for d in docs if d.metadata.get(\"source\")]\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14e03237-3526-4fb9-ae82-f495b0e84664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DB and delete any existing vectors with the same source metadata\n",
    "engine = create_engine(connection)\n",
    "placeholders = \", \".join([f\":s{i}\" for i in range(len(sources))]) or \"NULL\"\n",
    "\n",
    "sql = text(f\"\"\"\n",
    "    DELETE FROM langchain_pg_embedding\n",
    "    WHERE cmetadata->>'source' IN ({placeholders})\n",
    "    \"\"\")\n",
    "\n",
    "params = {f\"s{i}\": src for i, src in enumerate(sources)}\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # if there are no sources this will be a no-op\n",
    "    if sources:\n",
    "        conn.execute(sql, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7b9bdd9-dd95-438f-a3bf-5f2db2a3bff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'cats.txt'} there are cats in the pond\n",
      "{'source': 'ducks.txt'} there are also ducks in the pond\n"
     ]
    }
   ],
   "source": [
    "db = PGVector.from_documents(docs, embedding_model, connection=connection, collection_name=collection_name)\n",
    "\n",
    "results = db.similarity_search(\"pond animals\", k=3)\n",
    "for r in results:\n",
    "    print(r.metadata, r.page_content[:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825d40c-dde8-446b-b9ff-36bd177ddfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env (langchain)",
   "language": "python",
   "name": "lc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
