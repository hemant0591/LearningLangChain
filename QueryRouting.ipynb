{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "305496a2-c561-4032-a590-8c2bf2b2fcfd",
   "metadata": {},
   "source": [
    "#### When the data might be stored in more than one vector store, we need to be able to route the query to the appropriate datasource to retrieve relevant docs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61d5ef-eb6b-4e12-a1ff-f08217530565",
   "metadata": {},
   "source": [
    "### Logical Routing\n",
    "\n",
    "We give the LLM knowledge of the various data sources at our disposal and then let the LLM reason which data source to apply based on the userâ€™s query.\n",
    "In order to achieve this, we make use of function-calling models like GPT-3.5 Turbo to help classify each query into one of the available routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c7ad0d-b4f5-46c2-a058-ad8e247409db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8725f6ae-f85f-4f33-b2e0-b6b0928baa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user's query to the most relevant datasource.\"\"\"\n",
    "    datasource: Literal[\"python_docs\", \"js_docs\"] = Field(\n",
    "        description=\"\"\"Given users question, choose which data source is most relevant.\"\"\",\n",
    "    )\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "system = \"\"\"You are an expert at routing a user question to the relevant data source.\n",
    "Based on the programming language the question is referring to, route it to the relevant data source.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "router = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3719d10c-e525-4a83-b457-8afbe0af9d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RouteQuery(datasource='python_docs'), 'python_docs')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"Why doesn't the following code work: \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"])\n",
    "prompt.invoke(\"french\")\n",
    "\"\"\"\n",
    "\n",
    "result = router.invoke({\"question\" : question})\n",
    "result, result.datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a228a2-aad1-4847-9a5f-42074363becb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env (langchain)",
   "language": "python",
   "name": "lc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
