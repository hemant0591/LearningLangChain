{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a81c58b-7d7e-4f67-b74d-4c50d34c3c2e",
   "metadata": {},
   "source": [
    "### RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval\n",
    "\n",
    "RAG systems need to handle lower-level questions that reference specific facts found in a single document or higher-level questions that distill ideas that span many documents. Handling both types of questions can be a challenge with typical k-nearest neighbors (k-NN) retrieval over document chunks.\n",
    "\n",
    "RAPTOR is an effective strategy that involves creating document summaries that capture higher-level concepts, embedding and clustering those documents, and then summarizing each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2707f2ae-d02b-413f-a2fb-cd32f0b2f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import List, Optional, Dict, Any\n",
    "from dataclasses import dataclass, asdict\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7408415b-c1af-4c41-aa93-504faa0cd3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_postgres.vectorstores import PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0f3b8d-7d7c-4b8d-bc92-5f815ea6ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "\n",
    "CONNECTION = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "COLLECTION = \"hp_books\"\n",
    "\n",
    "EMBED_MODEL = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "SUMMARIZER = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "PROMPT_TEXT = \"Summarize following text concisely in 1-2 sentences, preserving key entities and facts:\\n\\n{text}\"\n",
    "PROMPT = ChatPromptTemplate.from_template(PROMPT_TEXT)\n",
    "GROUP_SIZE = 6 # branching factor: how many child nodes per parent\n",
    "TOP_K_ROOT = 3 # how many top root nodes to consider for initial query routing\n",
    "DESCEND_K = 2 # how many top children to keep at each descent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91c55d32-31d8-4009-a1fa-a3b16a16c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node dataclass to keep metadata\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    node_id: str\n",
    "    parent_id: Optional[str]\n",
    "    level: int # 0 = leaf (original chunk), >0 internal summary level\n",
    "    text: str\n",
    "    source: Optional[str] = None\n",
    "    extra: Dict[str, Any] = None # optional field for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30c0bc94-d4e5-43c0-9418-273301ca251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reptor_tree(doc_path: str, chunk_size=1000, chunk_overlap=100, group_size=GROUP_SIZE):\n",
    "    # load chunks\n",
    "    loader = TextLoader(doc_path, encoding='utf-8')\n",
    "    raw_docs = loader.load()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    leaf_chunks: List[Document] = splitter.split_documents(raw_docs)\n",
    "\n",
    "    # create lead nodes\n",
    "    leaves: List[Node] = []\n",
    "    for i, ch in enumerate(leaf_chunks):\n",
    "        leaves.append(Node(node_id=uuid.uuid4(), parent_id=None, level=0, text=ch.page_content, source=getattr(ch, 'metadata', {}).get('source', doc_path)))\n",
    "\n",
    "    # recursively create parent summaries\n",
    "    all_levels = {0: leaves} # dict level -> List[Nodes]\n",
    "    current_level = 0 # start at level 0\n",
    "    while len(all_levels[current_level]) > 1:\n",
    "        children = all_levels[current_level] # get the Nodes associated with current level\n",
    "        parents: List[Node] = []\n",
    "\n",
    "        # group children in contiguous group of size group_size\n",
    "        num_groups = ceil(len(children) / group_size)\n",
    "        for i in range(num_groups):\n",
    "            grouped_children = children[i * group_size : (i + 1) * group_size]\n",
    "            concat_text = '\\n\\n'.join([ch.text for ch in grouped_children])\n",
    "\n",
    "            # summarize using LLM\n",
    "            prompt_filled = PROMPT.format(text=concat_text)\n",
    "            resp = SUMMARIZER.invoke(prompt_filled)\n",
    "\n",
    "            # normalize response text\n",
    "            summary_text = resp.content if hasattr(resp, 'content') else str(resp)\n",
    "            parent_node = Node(node_id=str(uuid.uuid4()), parent_id=None, level=current_level+1, text=summary_text, source=None)\n",
    "\n",
    "            # link children to this parent\n",
    "            for ch in grouped_children:\n",
    "                ch.parent_id = parent_node.node_id\n",
    "            \n",
    "            parents.append(parent_node)\n",
    "        current_level += 1\n",
    "        all_levels[current_level] = parents\n",
    "\n",
    "    # collect all nodes (flatten)\n",
    "    nodes = []\n",
    "    max_level = max(all_levels.keys())\n",
    "    for lvl in range(max_level, -1, -1):\n",
    "        nodes.extend(all_levels[lvl])\n",
    "\n",
    "    return nodes, max_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db398ac-ae66-4e85-b6dc-828783614a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env (langchain)",
   "language": "python",
   "name": "lc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
